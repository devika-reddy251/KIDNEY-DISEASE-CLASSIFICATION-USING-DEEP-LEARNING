import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from imblearn.over_sampling import SMOTE
from PIL import Image

# Parameters
IMG_HEIGHT = 128
IMG_WIDTH = 128
BATCH_SIZE = 32
DATA_DIR = '../CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'  # adjust path if needed

classes = ['Cyst', 'Normal', 'Stone', 'Tumor']

def load_data(data_dir, classes, img_height, img_width):
    images = []
    labels = []
    for idx, cls in enumerate(classes):
        cls_dir = os.path.join(data_dir, cls)
        for fname in os.listdir(cls_dir):
            fpath = os.path.join(cls_dir, fname)
            try:
                img = Image.open(fpath).convert('RGB')
                img = img.resize((img_width, img_height))
                img_array = np.array(img)
                images.append(img_array)
                labels.append(idx)
            except Exception as e:
                print(f"Error loading image {fpath}: {e}")
    images = np.array(images, dtype='float32') / 255.0
    labels = np.array(labels)
    return images, labels

X, y = load_data(DATA_DIR, classes, IMG_HEIGHT, IMG_WIDTH)
print("Loaded:", X.shape, y.shape)


# Only use SMOTE if classes are very imbalanced
nsamples, h, w, c = X.shape
X_flat = X.reshape((nsamples, h*w*c))
sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X_flat, y)
X = X_res.reshape((-1, h, w, c))
y = y_res


X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
X_val, X_test = train_test_split(X_tmp, test_size=0.5, random_state=42, stratify=y_tmp)


model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    MaxPooling2D((2,2)),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Dropout(0.25),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(len(classes), activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.summary()



history = model.fit(
    X_train, y_train,
    epochs=20,
    batch_size=BATCH_SIZE,
    validation_data=(X_val, y_val)
)


model.save('../models/saved_model.h5')  # Path to your models folder


# Predict on test set
y_pred_probs = model.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)

# Classification Report
print(classification_report(y_test, y_pred, target_names=classes))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()


# Accuracy
plt.figure()
plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.legend()
plt.title("Accuracy over epochs")
plt.show()

# Loss
plt.figure()
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='val_loss')
plt.legend()
plt.title("Loss over epochs")
plt.show()


