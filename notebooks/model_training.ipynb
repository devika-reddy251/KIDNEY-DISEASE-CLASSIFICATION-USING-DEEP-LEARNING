import os
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
d
# Constants - update these paths/sizes as needed
DATA_DIR = r'C:\Users\SHIVAKUMAR\Desktop\KIDNEY\venv\CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone'
CLASSES = ['Normal', 'Cyst', 'Tumor', 'Stone']
IMG_HEIGHT, IMG_WIDTH = 128, 128
BATCH_SIZE = 32
EPOCHS = 15
MODEL_SAVE_PATH = 'models/saved_model.h5'

def load_data(data_dir, classes, img_height, img_width):
    images = []
    labels = []
    for idx, cls in enumerate(classes):
        cls_folder = os.path.join(data_dir, cls)
        if not os.path.exists(cls_folder):
            print(f"Warning: Folder not found: {cls_folder}")
            continue
        for fname in os.listdir(cls_folder):
            fpath = os.path.join(cls_folder, fname)
            try:
                img = Image.open(fpath).convert('RGB')
                img = img.resize((img_width, img_height))
                img_array = np.array(img, dtype='float32') / 255.0
                images.append(img_array)
                labels.append(idx)
            except Exception as e:
                print(f"Skipping {fpath}: {e}")
    return np.array(images), np.array(labels)

def build_model(input_shape, num_classes):
    model = Sequential([
        Conv2D(32, (3,3), activation='relu', input_shape=input_shape),
        MaxPooling2D(2,2),
        Conv2D(64, (3,3), activation='relu'),
        MaxPooling2D(2,2),
        Conv2D(128, (3,3), activation='relu'),
        MaxPooling2D(2,2),
        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

def main():
    print("Loading data...")
    X, y = load_data(DATA_DIR, CLASSES, IMG_HEIGHT, IMG_WIDTH)
    print(f"Data loaded. Images: {X.shape}, Labels: {y.shape}")

    if len(X) == 0 or len(y) == 0:
        print("No data found. Please check dataset path and contents.")
        return

    # Print class distribution
    unique, counts = np.unique(y, return_counts=True)
    print("Class distribution:", dict(zip(CLASSES, counts)))

    # Split data with stratification and fallback
    try:
        X_train, X_temp, y_train, y_temp = train_test_split(
            X, y, test_size=0.3, stratify=y, random_state=42)
        X_val, X_test, y_val, y_test = train_test_split(
            X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)
        print("Stratified split successful.")
    except ValueError as e:
        print(f"Stratified split failed: {e}")
        print("Using random split instead.")
        X_train, X_temp, y_train, y_temp = train_test_split(
            X, y, test_size=0.3, random_state=42)
        X_val, X_test, y_val, y_test = train_test_split(
            X_temp, y_temp, test_size=0.5, random_state=42)

    print(f"Train set: {X_train.shape}, Val set: {X_val.shape}, Test set: {X_test.shape}")

    # Build and train model
    model = build_model((IMG_HEIGHT, IMG_WIDTH, 3), len(CLASSES))
    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

    print("Training model...")
    history = model.fit(
        X_train, y_train,
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        validation_data=(X_val, y_val),
        callbacks=[early_stop]
    )

    # Save the model
    os.makedirs('models', exist_ok=True)
    model.save(MODEL_SAVE_PATH)
    print(f"Model saved to {MODEL_SAVE_PATH}")

    # Evaluate on test set
    loss, acc = model.evaluate(X_test, y_test, verbose=0)
    print(f"Test accuracy: {acc*100:.2f}%")

if __name__ == "__main__":
    main()
